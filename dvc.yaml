stages:
  preprocess:
    cmd: python src/data_processing.py --train_input data/raw/train.csv --test_input data/raw/test.csv --output_path data/processed --baseline_sample_path data/baseline_sample
    deps:
      - data/raw/test.csv
      - data/raw/train.csv
      - src/data_processing.py
    outs:
      - data/processed
      - data/baseline_sample

  # --- NOTE: Drift detection is temporarily disabled for direct model experimentation. ---
  # ---       To restore the full automated pipeline, comment out the 'train'     ---
  # ---       stage below and uncomment 'validate_data' and 'trigger_retraining'. ---

  train:
    cmd: >-
      python src/train.py 
      --train_data data/processed/train 
      --model_out model/spark_model 
      --spark_driver_memory ${spark_configs[${experiment_profile}].driver_memory} 
      --spark_executor_cores ${spark_configs[${experiment_profile}].executor_cores} 
      --spark_shuffle_partitions ${spark_configs[${experiment_profile}].shuffle_partitions}
    deps:
      - data/processed
      - src/train.py
    params:
      - experiment_profile
      - spark_configs
    outs:
      - model/spark_model
    metrics:
      - metrics.json:
          cache: false

